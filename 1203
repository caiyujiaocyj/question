def init_worker_compute_confidence(init_args):
    """
    20251120, mcwei, compute confidence.
    :return:
    """
    global g_lst_cyn, g_lst_pc
    g_lst_cyn = init_args[0]
    g_lst_pc = init_args[1]
    return

def compute_confidence_mp(lst_cyn, lst_pc):
    """
    20251120, mcwei, compute confidence.
    :return:
    """
    lst_args = [[i] for i in range(len(lst_cyn))]

    if NUM_PROC_CONFIDENCE > 0:
        lst_res = callback_multiprocessing(
            compute_confidence_single,
            lst_args,
            NUM_PROC_CONFIDENCE,
            batch_size=50,
            init_worker=init_worker_compute_confidence,
            initargs=(lst_cyn, lst_pc)
        )
        for res in lst_res:
            for i in res:
                for confidence in LST_CONFIDENCE:
                    lst_cyn[i][confidence] = res[i][confidence]
    else:
        for i in tqdm(range(len(lst_cyn))):
            res = compute_confidence_single(i)
            for confidence in LST_CONFIDENCE:
                lst_cyn[i][confidence] = res[i][confidence]
    return


def init_proc_log(i):
    handlers_=[logging.FileHandler(os.path.join(PATH_OUTPUT, f"merge_cyns_{now.month}_{now.day}_{now.hour}_{now.minute}_{i}_proc.log"), mode='a'),  # 输出到文件
        ]  # 输出到控制台（可选） #test
    formater_str = '%(asctime)s [%(levelname)s] %(message)s'
    formatter = logging.Formatter(formater_str)
    logger_i = logging.getLogger(f"log_proc_{i}")
    logger_i.setLevel(logging.DEBUG)  # 确保低于或等于 DEBUG
    for handler in handlers_:
        handler.setFormatter(formatter)
        logger_i.addHandler(handler)
    return logger_i

def proc_one_cluster(i, config):#in fact not just one cluster, but a sub-range (start, end).
    logger = init_proc_log(i)

    lst_cluster = config.get('lst_cluster', None)
    lst_pcs = config.get('lst_pcs', None)
    lst_cyns, id_dir, firstTime, cnt_proc = config.get('lst_cyns', None), config.get('id_dir', None), config.get('firstTime', None), config.get('cnt_proc', 2)
    cnt_all = len(lst_cluster)
    num_each_proc = cnt_all // cnt_proc
    start,end = i*num_each_proc, (i+1)*num_each_proc
    if i==cnt_proc-1: end = cnt_all

    res_all = []
    for ii in range(start, end):
        cluster_cyn = lst_cluster[ii]
        lst_pc_i = merge_pc_clusters(lst_pcs, cluster_cyn) #把cluster_cyn里的所有点云(每个点云在lst_pcs里)合并起来.
        lst_cyn_fitted, lst_inlier, cluster_cyn = cluster_cyn_api_single(ii, lst_cluster, lst_pc_i, lst_cyns, id_dir, firstTime, logger)
        #cluster_all[cluster_cyn[0]] = dict(cylinder=lst_cyn_fitted, cluster=cluster_cyn)
        res_all.append((lst_cyn_fitted, lst_inlier, cluster_cyn))
    return res_all #lst_cyn_fitted, lst_inlier, cluster_cyn

def cluster_cyn_api(lst_cyns, lst_pcs, thr_centerline_dist, id_dir, firstTime, logger):#firstTime: True的时候，表示lst_cyns里的圆柱是centerline算法的，需要重新估计.
    is_diff_dir = id_dir>=UNKNOWN_DIR
    lst_cluster = cluster_cyn_sub(lst_cyns, lst_pcs, thr_centerline_dist, is_diff_dir, logger)  #对圆柱做聚类.
    len_clusters = [len(clu) for clu in lst_cluster] #just for debug.
    if logger: logger.debug(f"first time {firstTime}, cluster num {len(lst_cluster)}, cluster lens {len_clusters}")

    #merge pc and do cylinder fitting.
    cluster_all = {} #用dict，key是选择的度最高的node的id.  这个数据好像没用.
    lst_cyns_o, lst_pcs_o = [],[] #cyn fitting的结果，cyn和pc是对应的.
    cnt_fitting = get_fitting_cnt(lst_cluster, firstTime)
    do_single_thread = not (NUM_PROC_CYN>1 and len(lst_cluster)>600)
    if for_debug: do_single_thread = True
    #do_single_thread = not (NUM_PROC_CYN>1 and cnt_fitting>600)  #effect not good. time cost is more related to pt num than cyn num.
    if logger: logger.debug(f"cnt fitting {cnt_fitting}, num cluster {len(lst_cluster)}")
    if do_single_thread:
        if logger: logger.debug(f"single thread cyn fitting")
        for i in tqdm(range(len(lst_cluster)), 'Fitting cylinders.'): #cluster_cyn in lst_cluster:
            cluster_cyn = lst_cluster[i]
            if for_debug:
                if 2658 in cluster_cyn: 
                    edges = find_edges_debug(cluster_cyn, lst_cyns, lst_pcs, thr_centerline_dist, is_diff_dir)
                    for ii in cluster_cyn:
                        save_auto_labeling_format_zhh(lst_cyns[ii], lst_pcs[ii], PATH_OUTPUT, id_dir, ii, firstTime)
                    pdb.set_trace()
                else: continue
            lst_pc_i = merge_pc_clusters(lst_pcs, cluster_cyn) #把cluster_cyn里的所有点云(每个点云在lst_pcs里)合并起来.
            lst_cyn_fitted, lst_inlier, cluster_cyn = cluster_cyn_api_single(i, lst_cluster, lst_pc_i, lst_cyns, id_dir, firstTime, logger)
            assert len(lst_cyn_fitted)==len(lst_inlier), f'error for cyn fitting: cyn num {len(lst_cyn_fitted)}, pc num {len(lst_inlier)}'
            if for_debug:
                for i in range(len(lst_cyn_fitted)):  
                    if lst_cyn_fitted[i] is not None:
                        save_auto_labeling_format_zhh(lst_cyn_fitted[i], lst_inlier[i], PATH_OUTPUT, 5000, i, firstTime)
            cluster_all[cluster_cyn[0]] = dict(cylinder=lst_cyn_fitted, cluster=cluster_cyn)
            lst_cyns_o.extend(lst_cyn_fitted)
            lst_pcs_o.extend(lst_inlier)
    else: # Multiprocessing
        if logger: logger.debug(f"multi thread cyn fitting")
        random.shuffle(lst_cluster) #重排一下，因为原始的序列，排在前面的都是比较长的cluster.
        cnt_proc = get_proc_num(cnt_fitting)
        public_config = {"lst_cluster": lst_cluster, "lst_pcs": lst_pcs,"lst_cyns": lst_cyns,"id_dir": id_dir,"firstTime": firstTime, "cnt_proc": cnt_proc}
        task_for_worker = functools.partial(proc_one_cluster, config=public_config) #使用 functools.partial 绑定公共参数
        cnt_all = len(lst_cluster)
        with concurrent.futures.ProcessPoolExecutor(max_workers=cnt_proc) as executor:
            results_iterator = executor.map(task_for_worker, range(cnt_proc))
            for item in results_iterator:
              for unit in item:
                lst_cyn_fitted, lst_inlier, cluster_cyn = unit
                assert len(lst_cyn_fitted)==len(lst_inlier), f'error for cyn fitting multi-proc: cyn num {len(lst_cyn_fitted)}, pc num {len(lst_inlier)}'
                cluster_all[cluster_cyn[0]] = dict(cylinder=lst_cyn_fitted, cluster=cluster_cyn)
                lst_cyns_o.extend(lst_cyn_fitted)
                lst_pcs_o.extend(lst_inlier)
        if logger: logger.debug(f"finish multi thread cyn fitting")

    return lst_cyns_o, lst_pcs_o, cluster_all

#处理一个gt_dir的所有components.
#lst_cyns: 所有pred cylinder的lst.
def cluster_with_centerline(lst_cyns, dic_uid2pc, thr_centerline_dist, id_dir, logger): #id_dir: the id of gt_direction.
    #set up all edges. node是每个cyn，即lst_cyns is node set.
    lst_pcs = [dic_uid2pc[cyn['uid']] for cyn in lst_cyns]
    assert len(lst_pcs)==len(lst_cyns), 'error. get pc wrong.'
    if logger: logger.debug(f'proc direction {id_dir}, total cyns: {len(lst_cyns)}')

    #first time merge: input cyns are from centerline-based algorithm.
    lst_cyns_o, lst_pcs_o, cluster_all_1 = cluster_cyn_api(lst_cyns, lst_pcs, thr_centerline_dist, id_dir, True, logger)

    #提取其中非non的cylinder.
    lst_cyns_o_valid, lst_pcs_o_valid = [],[]
    for i in range(len(lst_cyns_o)):
        if lst_cyns_o[i] is not None:
            lst_cyns_o_valid.append(lst_cyns_o[i])
            lst_pcs_o_valid.append(lst_pcs_o[i])

    #second time.
    lst_cyns_f, lst_pcs_f, cluster_all_2 = cluster_cyn_api(lst_cyns_o_valid, lst_pcs_o_valid, thr_centerline_dist, id_dir, False, logger)
    return cluster_all_1, cluster_all_2, lst_pcs, lst_cyns_f, lst_pcs_f

def init_log():
    global g_logger
    g_logger = []
    handlers = []
    for i in range(1): #(NUM_PROC_CYN): 这样不行，需要在子进程里面创建logger.
        handlers_=[logging.FileHandler(os.path.join(PATH_OUTPUT, f"merge_cyns_{now.month}_{now.day}_{now.hour}_{now.minute}_{i}.log"), mode='w'),  # 输出到文件
            logging.StreamHandler()]  # 输出到控制台（可选） #test
        handlers.append(handlers_)
        formater_str = '%(asctime)s [%(levelname)s] %(message)s'
        formatter = logging.Formatter(formater_str)
        logger_i = logging.getLogger(__name__)
        logger_i.setLevel(logging.DEBUG)  # 确保低于或等于 DEBUG
        for handler in handlers_:
            handler.setFormatter(formatter)
            logger_i.addHandler(handler)
        g_logger.append(logger_i)
    return handlers


def load_cyns(dir_cyn):
    """
    :param dir_cyn:
    :return:
        A list of length cylinders.
        lst_cyn[i] is a dict, keys are 'start', 'end', 'radius', 'length', 'direction', 'ind_clustered', 'in_inlier'.
    """
    # lst_path_cyn = glob.glob(os.path.join(dir_cyn, "*.pts.json"))
    # lst_path_cyn.sort()
    lst_cyn = []
    # for path_cyn in tqdm(lst_path_cyn, 'Loading fitted cylinders'):
    #     lst_cyn.extend(json.load(open(path_cyn, 'r')))

    lst_cyn = []
    lst_path_res_fitting = glob.glob(os.path.join(dir_cyn))
    lst_path_res_fitting.sort()
    for path_res_fitting in tqdm(lst_path_res_fitting, 'Loading fitting results.'):
        res_fitting = pickle.load(open(path_res_fitting, 'rb'))
        """
        Outputs of components fitting.
        res_fitting is a dict, 
        res_fitting['ind_pts'] is a point indice. pc[res_fitting['ind_pts']] is the input points of component fitting.
            res_fitting['ind_pts'] = np.arange(n_pc), which is useless
        res_fitting['results'] is the component fitting result. It is a list.
        res_fitting['ind_pts'][i] is the information of a fitted cylinder.
        res_fitting['ind_pts'][i]['ind_clustered'] is the point indice of a cluster. Use it to index pc[res_fitting['ind_pts']].
        res_fitting['ind_pts'][i]['ind_inlier'] is the inlier point indice.  Use it to index pc[res_fitting['ind_pts']].
        res_fitting['ind_pts'][i]['d'] is the estimated pipe direction (for all points) using predicted normals.
        res_fitting['ind_pts'][i]['start'] 
        res_fitting['ind_pts'][i]['end']
        res_fitting['ind_pts'][i]['radius']
        res_fitting['ind_pts'][i]['length']
        """

        # Add block name into each cyn.
        for cyn in res_fitting['results']:
            cyn['block'] = os.path.basename(path_res_fitting).strip('.pts.pkl')
        lst_cyn.extend(res_fitting['results'])

    lst_cyn = list(filter(lambda x: 'start' in x, lst_cyn))
    for i, cyn in enumerate(lst_cyn):
        direction = np.subtract(cyn['end'], cyn['start'])
        norm = np.linalg.norm(direction)
        if norm != 0:
            direction = direction / norm
        cyn['direction'] = direction
        cyn['uid'] = i
        #assert 'unified_id' in cyn, 'error. cyn fitting should output an id'  #todo: 需要修改cyn fitting的code，有这个字段。
        if not ('unified_id' in cyn): cyn['unified_id'] = cyn['uid']
    return lst_cyn

#对于lst_cyns的每个圆柱，得到对应的点云.
def get_pc_of_cyns(dir_cyn, lst_cyn, key='ind_clustered', merge_pc=True, pts_path=None):
    """
    :param dir_cyn:
    :param lst_cyn: list of cylinders.
    :param key: 'ind_clustered' or 'ind_inlier' 前者返回cluster点，后者返回inlier点.
    :param merge_pc: 是否把对应于每个圆柱的点云做合并
    :return:
        (n_pc, 17) if merge_pc
        list of (n_pc, 17) if not merge_pc
    """
    dir_tmp = os.path.join(os.path.dirname(dir_cyn), 'tmp')
    os.makedirs(dir_tmp, exist_ok=True)
    path_pcs_tmp = os.path.join(dir_tmp, 'uid2pc_1113.pkl')
    path_bboxes_tmp = os.path.join(dir_tmp, 'uid2bbox_1113.pkl')

    t0 = time.time()

    if os.path.isfile(path_pcs_tmp) and os.path.isfile(path_bboxes_tmp):
        dic_uid2pc = pickle.load(open(path_pcs_tmp, 'rb'))
        dic_uid2bbox = pickle.load(open(path_bboxes_tmp, 'rb'))
    else:
        dic_block2pc = {}  # 缓存，如果多个 cyn 来自同一个 block，只需要读取一次该 block 的 pc。
        dic_uid2pc = {}
        dic_uid2bbox = {}
        for cyn in tqdm(lst_cyn, 'Loading PCs.'):
            block = cyn['block']
            if pts_path is None:
                path_pc = os.path.join(dir_cyn if os.path.isdir(dir_cyn) else os.path.dirname(dir_cyn),'../../',f"{block}.pts")
            else: path_pc = os.path.join(pts_path,f"{block}.pts")
            if block not in dic_block2pc: dic_block2pc[block] = np.loadtxt(path_pc)
            pc = dic_block2pc[block]

            # Retrieve points.
            ind = cyn[key]  # These indices are used to index pipe points, not all points.
            pc_pipe = pc[pc[:, 10] == 1]
            pc_final = pc_pipe[ind][:, :3]
            dic_uid2pc[cyn['uid']] = pc_final
            dic_uid2bbox = [pc_final[:, :3].min(0), pc_final[:, :3].max(0)]
        pickle.dump(dic_uid2pc, open(path_pcs_tmp, 'wb'))
        pickle.dump(dic_uid2bbox, open(path_bboxes_tmp, 'wb'))

    t1 = time.time()
    g_logger[0].debug(f"Load PC time consumption: {t1 - t0}s")

    if merge_pc:
        dic_uid2pc = np.vstack(dic_uid2pc.values())
    return dic_uid2pc, dic_uid2bbox


def convert_cylinder2bbox(cyn, tolerance=0):
    """
    Convert a cylinder 2 a bbox
    :param cyn:
    :param tolerance:
    :return:
    """
    start = np.array(cyn['start'])
    end = np.array(cyn['end'])
    radius = cyn['radius']
    axis = end - start
    length = np.linalg.norm(axis)

    axis_unit = axis / length
    r_proj = radius * np.sqrt(1 - axis_unit ** 2)

    bbox_min = np.minimum(start, end) - r_proj - tolerance
    bbox_max = np.maximum(start, end) + r_proj + tolerance
    return bbox_min, bbox_max


def bbox_intersect_3d(bbox1, bbox2):
    """
    判断两个3D边界框是否相交

    参数:
        bbox1: ((xmin1, ymin1, zmin1), (xmax1, ymax1, zmax1))
        bbox2: ((xmin2, ymin2, zmin2), (xmax2, ymax2, zmax2))

    返回:
        bool: True表示相交，False表示不相交
    """
    # 解构边界框坐标
    (xmin1, ymin1, zmin1), (xmax1, ymax1, zmax1) = bbox1
    (xmin2, ymin2, zmin2), (xmax2, ymax2, zmax2) = bbox2

    # 检查三个轴上的投影是否重叠
    x_overlap = (xmin1 <= xmax2) and (xmax1 >= xmin2)
    y_overlap = (ymin1 <= ymax2) and (ymax1 >= ymin2)
    z_overlap = (zmin1 <= zmax2) and (zmax1 >= zmin2)

    # 三个轴都重叠才表示相交
    return x_overlap and y_overlap and z_overlap


def point_to_line_distance(pts, A, B):
    """

    :param pts: (N, 3)
    :param A: (3,)
    :param B: (3,)
    :return: (N,)
    """
    pts = pts[:, :3]
    A = np.array(A)
    B = np.array(B)
    AB = B - A
    if np.linalg.norm(AB) < 1e-10:
        return np.linalg.norm(pts - A, axis=1)
    AP = pts - A
    cross_product = np.cross(AP, AB)
    cross_norm = np.linalg.norm(cross_product, axis=1)

    dis = cross_norm / np.linalg.norm(AB)
    return dis


def point_to_line_distance_v2(pts, A, B):
    """

    :param pts: (N, 3)
    :param A: (3,)
    :param B: (3,)
    :return: (N,)
    """
    A = np.array(A)
    B = np.array(B)
    AB = B - A
    if np.linalg.norm(AB) < 1e-10:
        return np.linalg.norm(pts - A, axis=1)
    AP = pts - A
    cross_product = np.cross(AP, AB)
    cross_norm = np.linalg.norm(cross_product, axis=1)

    dis = cross_norm / np.linalg.norm(AB)
    return dis


def get_pc_mask_inside_cylinder_org(pts, start, end, radius, len_ext=0.02):
    """

    :param pts: (N, 3)
    :param start: (3,)
    :param end: (3,)
    :param radius:
    :param len_ext: extending length (unit is m), length of the cylinder used for indices computation is len_cyl + len_ext.
    :return:
        mask_inside: (N,)
    """
    direction = end - start  # Cylinder direction.
    len_cyl = np.linalg.norm(direction)  # Cylinder length.
    direction = direction / len_cyl  # Normalized cylinder direction.

    if len_cyl < 1e-6:
        mask_inside = np.zeros_like(pts[:, 0], dtype=bool)
        return mask_inside

    # Compute the mask: distance<pc, axis> < radius.
    mask_inside_along_normal = point_to_line_distance_v2(pts, start, end) < radius

    # Compute the mask: pc is between start_ext and end_ext.
    start_ext = start - direction * len_ext  # Extended start.
    end_ext = end + direction * len_ext  # Extended end.
    ES = start_ext - end_ext  # (3,)
    SE = -ES  # (3,)
    SP = pts - start_ext  # (N, 3)
    EP = pts - end_ext  # (N, 3)
    mask_inside_along_direction = (np.sum(SP * SE, axis=1) > 0) & (np.sum(EP * ES, axis=1) > 0)

    mask_inside = mask_inside_along_normal & mask_inside_along_direction
    return mask_inside


def cal_overlap_IoS(cynA, cynB, size_voxel=0.01):
    """
    20251203, mcwei, decrease time consumption when any pipe is too long.
    :param cynA:
    :param cynB:
    :param size_voxel:
    :return:
    """
    cynL = cynA if cynA['length'] > cynB['length'] else cynB  # Longer pipe.
    cynS = cynB if cynA['length'] > cynB['length'] else cynA  # Shorter pipe
    bbox = cynS.get('bbox', convert_cylinder2bbox(cynS))
    xmin, ymin, zmin = bbox[0]
    xmax, ymax, zmax = bbox[1]
    xs = np.arange(xmin, xmax, size_voxel)
    ys = np.arange(ymin, ymax, size_voxel)
    zs = np.arange(zmin, zmax, size_voxel)
    pc = np.stack(np.meshgrid(xs, ys, zs), axis=-1).reshape(-1, 3)
    mask_L = get_pc_mask_inside_cylinder_org(pc, cynL['start'], cynL['end'], cynL['radius'], len_ext=0)

    I = mask_L.sum()
    S = len(pc)
    IoS = I / (S + 1e-6)
    return IoS


def cal_overlap_between_cyns(cynA, cynB, size_voxel=0.01):
    bbox1 = cynA.get('bbox', convert_cylinder2bbox(cynA))
    bbox2 = cynB.get('bbox', convert_cylinder2bbox(cynB))
    bbox = (np.min([bbox1[0], bbox2[0]], axis=0), np.max([bbox1[1], bbox2[1]], axis=0))
    xmin, ymin, zmin = bbox[0]
    xmax, ymax, zmax = bbox[1]
    xs = np.arange(xmin, xmax, size_voxel)
    ys = np.arange(ymin, ymax, size_voxel)
    zs = np.arange(zmin, zmax, size_voxel)
    pc = np.stack(np.meshgrid(xs, ys, zs), axis=-1).reshape(-1, 3)

    mask_A = get_pc_mask_inside_cylinder_org(pc, cynA['start'], cynA['end'], cynA['radius'], len_ext=0)
    mask_B = get_pc_mask_inside_cylinder_org(pc, cynB['start'], cynB['end'], cynB['radius'], len_ext=0)
    mask_I = mask_A & mask_B

    A = mask_A.sum()
    B = mask_B.sum()
    I = mask_I.sum()

    IoA = I / (A + 1e-6)
    IoB = I / (B + 1e-6)
    IoU = I / (A + B - I + 1e-6)

    return IoA, IoB, IoU


def filter_cyns(lst_cyn, lst_pc, logger): #single thread version.
    """
    1. 删除 inlier 点太少的
    2. 删除太短的
    3. 遍历所有距离不远的 pair：
      3.1. 如果 overlap (I/S) 比较大则删掉短的。
      3.2. 如果方向不同，且 A 的 inlier 几乎都在 B_ext 上，但是 B 的 inlier 有很多不在 A_ext 上，则删掉 A。
    :param lst_cyn:
    :param lst_pc:
    :param logger:
    :return:
    """
    # Add bbox to each cyn.
    for i in range(len(lst_cyn)):
        lst_cyn[i]['bbox'] = convert_cylinder2bbox(lst_cyn[i])
        lst_cyn[i]['bbox_extend'] = convert_cylinder2bbox(lst_cyn[i], THR_FILTER_BBOX_TOLERANCE)

    dir_cyn = args.path_cyns
    dir_save = (dir_cyn if os.path.isdir(dir_cyn) else os.path.dirname(dir_cyn)).replace(
        'save_for_vis', f'ifc_merge/{now.month}_{now.day}_{now.hour}_{now.minute}')
    os.makedirs(dir_save, exist_ok=True)
    pickle.dump(lst_cyn, open(f"{dir_save}/output2_cyns.pkl", 'wb'))
    pickle.dump(lst_pc, open(f"{dir_save}/output2_inliers.pkl", 'wb'))

    num_cyn = len(lst_cyn)

    # 1. 删除 inlier 点太少的
    mask_low_inlier = np.array([len(pc) > THR_FILTER_MIN_NUM_INLIER for pc in lst_pc])

    # 2. 删除太短的
    mask_short = np.array([cyn['length'] > THR_FILTER_MIN_LEN for cyn in lst_cyn])

    mask_judge_by_inlier = np.ones(num_cyn, dtype=bool)
    # 遍历所有 pair：
    order = np.argsort([cyn['length'] for cyn in lst_cyn])  # 先用长度排个序，从短的开始删除
    lst_cyn_sort_by_len = [lst_cyn[o] for o in order]
    for idx1 in tqdm(range(num_cyn)):
        idx1_ori = order[idx1]
        cyn1 = lst_cyn_sort_by_len[idx1]
        dir1 = cyn1['direction']
        bbox1 = cyn1['bbox_extend']
        pc1 = lst_pc[idx1_ori]
        dist_inlier1_cyn1 = np.abs(point_to_line_distance(pc1, cyn1['start'], cyn1['end']) - cyn1['radius'])
        dist_inlier1_cyn1_max = dist_inlier1_cyn1.max()
        for idx2 in range(idx1 + 1, num_cyn):
            idx2_ori = order[idx2]
            cyn2 = lst_cyn_sort_by_len[idx2]  # cyn2 更长
            dir2 = cyn2['direction']
            bbox2 = cyn2['bbox_extend']

            # 跳过距离比较远的 pair
            if not bbox_intersect_3d(bbox1, bbox2):
                continue

            # 对于方向不同的两个圆柱，圆柱 A 的内点大部分都在 B 上，B 的内点大部分都不在 A 上，则删除 A。
            if np.dot(dir1, dir2) < 1-1e-4:
                pc2 = lst_pc[idx2_ori]

                dist_inlier2_cyn2 = np.abs(point_to_line_distance(pc2, cyn2['start'], cyn2['end']) - cyn2['radius'])

                dist_inlier2_cyn2_max = dist_inlier2_cyn2.max()

                dist_inlier2_cyn1 = np.abs(point_to_line_distance(pc2, cyn1['start'], cyn1['end']) - cyn1['radius'])
                dist_inlier1_cyn2 = np.abs(point_to_line_distance(pc1, cyn2['start'], cyn2['end']) - cyn2['radius'])

                # ratio_i2_in_c1 = (dist_inlier2_cyn1 <= dist_inlier1_cyn1_max).sum() / len(pc2)
                # ratio_i1_in_c2 = (dist_inlier1_cyn2 <= dist_inlier2_cyn2_max).sum() / len(pc1)

                ratio_i2_in_c1 = (dist_inlier2_cyn1 <= max(dist_inlier1_cyn1_max, dist_inlier2_cyn2_max)).sum() / len(pc2)
                ratio_i1_in_c2 = (dist_inlier1_cyn2 <= max(dist_inlier1_cyn1_max, dist_inlier2_cyn2_max)).sum() / len(pc1)

                i1_in_c2 = ratio_i1_in_c2 > THR_FILTER_MAX_RATIO_INLIER
                i2_in_c1 = ratio_i2_in_c1 > THR_FILTER_MAX_RATIO_INLIER

                i1_not_in_c2 = ratio_i1_in_c2 < THR_FILTER_MIN_RATIO_INLIER
                i2_not_in_c1 = ratio_i2_in_c1 < THR_FILTER_MIN_RATIO_INLIER

                if i1_in_c2 and i2_not_in_c1:
                    # inlier1 都在 cyn2 上，但是 inlier2 不再 cyn1 上，说明 cyn1 不好
                    mask_judge_by_inlier[idx1_ori] = False
                    # if lst_cyn[idx1_ori]['name'] == '30': print(idx1, idx2)
                    continue

                if i2_in_c1 and i1_not_in_c2:
                    mask_judge_by_inlier[idx2_ori] = False
                    # if lst_cyn[idx2_ori]['name'] == '30': print(idx1, idx2)
                    continue

            # 对于任意方向的两个圆柱，如果两个圆柱 overlap 很大
            IoA, IoB, IoU = cal_overlap_between_cyns(cyn1, cyn2)

            if IoA > THR_FILTER_MAX_RATIO_OVERLAP and IoB > THR_FILTER_MAX_RATIO_OVERLAP:
                # todo: 可以尝试以下几种方式：删除短的；删除置信度低的；删除 IoX 明显小的。
                # 删除短的
                if cyn1['length'] > cyn2['length']:
                    mask_judge_by_inlier[idx2_ori] = False
                else:
                    mask_judge_by_inlier[idx1_ori] = False
            elif IoA > THR_FILTER_MAX_RATIO_OVERLAP and IoB <= THR_FILTER_MAX_RATIO_OVERLAP:

                mask_judge_by_inlier[idx1_ori] = False
            elif IoA <= THR_FILTER_MAX_RATIO_OVERLAP and IoB > THR_FILTER_MAX_RATIO_OVERLAP:
                mask_judge_by_inlier[idx2_ori] = False
            else:
                pass

    mask = mask_low_inlier & mask_short & mask_judge_by_inlier
    compute_confidence_mp(lst_cyn, lst_pc)  # 20251120, mcwei, compute confidence.

    check_io_of_filtering(lst_cyn, lst_pc, mask, args.path_cyns)  # 保存最终结果

    lst_cyn_filtered = [lst_cyn[i] for i in range(num_cyn) if mask[i]]
    lst_pc_filtered = [lst_pc[i] for i in range(num_cyn) if mask[i]]
    return lst_cyn_filtered, lst_pc_filtered


def filter_single(idx1, idx2, cyn1, cyn2, pc1, pc2):
    ind = set()
    dir1 = cyn1['direction']
    dir2 = cyn2['direction']

    # 对于方向不同的两个圆柱，圆柱 A 的内点大部分都在 B 上，B 的内点大部分都不在 A 上，则删除 A。
    if np.dot(dir1, dir2) < 1-1e-4:
        dist_inlier1_cyn1 = np.abs(point_to_line_distance(pc1, cyn1['start'], cyn1['end']) - cyn1['radius'])
        dist_inlier2_cyn2 = np.abs(point_to_line_distance(pc2, cyn2['start'], cyn2['end']) - cyn2['radius'])

        dist_inlier1_cyn1_max = dist_inlier1_cyn1.max()
        dist_inlier2_cyn2_max = dist_inlier2_cyn2.max()

        dist_inlier2_cyn1 = np.abs(point_to_line_distance(pc2, cyn1['start'], cyn1['end']) - cyn1['radius'])
        dist_inlier1_cyn2 = np.abs(point_to_line_distance(pc1, cyn2['start'], cyn2['end']) - cyn2['radius'])

        # ratio_i2_in_c1 = (dist_inlier2_cyn1 <= dist_inlier1_cyn1_max).sum() / len(pc2)
        # ratio_i1_in_c2 = (dist_inlier1_cyn2 <= dist_inlier2_cyn2_max).sum() / len(pc1)

        ratio_i2_in_c1 = (dist_inlier2_cyn1 <= max(dist_inlier1_cyn1_max, dist_inlier2_cyn2_max)).sum() / len(pc2)
        ratio_i1_in_c2 = (dist_inlier1_cyn2 <= max(dist_inlier1_cyn1_max, dist_inlier2_cyn2_max)).sum() / len(pc1)

        i1_in_c2 = ratio_i1_in_c2 > THR_FILTER_MAX_RATIO_INLIER
        i2_in_c1 = ratio_i2_in_c1 > THR_FILTER_MAX_RATIO_INLIER

        i1_not_in_c2 = ratio_i1_in_c2 < THR_FILTER_MIN_RATIO_INLIER
        i2_not_in_c1 = ratio_i2_in_c1 < THR_FILTER_MIN_RATIO_INLIER

        if i1_in_c2 and i2_not_in_c1:
            # inlier1 都在 cyn2 上，但是 inlier2 不再 cyn1 上，说明 cyn1 不好
            ind.add(idx1)
            # if lst_cyn[idx1_ori]['name'] == '30': print(idx1, idx2)

        if i2_in_c1 and i1_not_in_c2:
            ind.add(idx2)
            # if lst_cyn[idx2_ori]['name'] == '30': print(idx1, idx2)

    if len(ind) > 0:
        return ind

    # 对于任意方向的两个圆柱，如果两个圆柱 overlap 很大
    # 20251203, mcwei, decrease time consumption when any pipe is too long.
    if cyn1['length'] > THR_FILTER_MIN_LEN_MUST_RESERVE and cyn2['length'] > THR_FILTER_MIN_LEN_MUST_RESERVE:
        IoA = 0
        IoB = 0
    elif cyn1['length'] > THR_FILTER_MIN_LEN_MUST_RESERVE and cyn2['length'] <= THR_FILTER_MIN_LEN_MUST_RESERVE:
        IoA = 0
        IoB = cal_overlap_IoS(cyn1, cyn2)
    elif cyn1['length'] <= THR_FILTER_MIN_LEN_MUST_RESERVE and cyn2['length'] > THR_FILTER_MIN_LEN_MUST_RESERVE:
        IoA = cal_overlap_IoS(cyn1, cyn2)
        IoB = 0
    else:
        IoA, IoB, IoU = cal_overlap_between_cyns(cyn1, cyn2)

    if IoA > THR_FILTER_MAX_RATIO_OVERLAP and IoB > THR_FILTER_MAX_RATIO_OVERLAP:
        # todo: 可以尝试以下几种方式：删除短的；删除置信度低的；删除 IoX 明显小的
        # 删除短的
        if cyn1['length'] > cyn2['length']:
            ind.add(idx2)
        else:
            ind.add(idx1)
    elif IoA > THR_FILTER_MAX_RATIO_OVERLAP and IoB <= THR_FILTER_MAX_RATIO_OVERLAP:
        ind.add(idx1)
    elif IoA <= THR_FILTER_MAX_RATIO_OVERLAP and IoB > THR_FILTER_MAX_RATIO_OVERLAP:
        ind.add(idx2)
    else:
        pass
    return ind


def judge_bbox_intersect(idx1, idx2):
    global g_lst_cyn
    cyn1 = g_lst_cyn[idx1]
    cyn2 = g_lst_cyn[idx2]  # cyn2 更长
    bbox1 = cyn1['bbox_extend']
    bbox2 = cyn2['bbox_extend']
    if bbox_intersect_3d(bbox1, bbox2): return (idx1, idx2)
    else: return None


def init_worker(init_args):
    global g_lst_cyn
    g_lst_cyn = init_args


def filter_cyns_mp(lst_cyn, lst_pc, logger): #multi-process version.
    """multi-processing
    1. 删除 inlier 点太少的
    2. 删除太短的
    3. 遍历所有距离不远的 pair：
      3.1. 如果 overlap (I/S) 比较大则删掉短的。
      3.2. 如果方向不同，且 A 的 inlier 几乎都在 B_ext 上，但是 B 的 inlier 有很多不在 A_ext 上，则删掉 A。
    :param lst_cyn:
    :param lst_pc:
    :param logger:
    :return:
    """
    just_for_debug = lst_cyn is None
    if just_for_debug:
        path_cyn_file = "/media/samsung/samsung/recons_res/res_zhh_1202/cylinder_fitting_1F_newclusterv2round2_a0.001_wo_R2C1st_wo_R2C2nd_wo_merge_12_2_18_23/ifc_merge/12_2_18_34/output2_cyns.pkl"
        lst_cyn = pickle.load(open(path_cyn_file, 'rb'))
        lst_pc = pickle.load(open("/media/samsung/samsung/recons_res/res_zhh_1202/cylinder_fitting_1F_newclusterv2round2_a0.001_wo_R2C1st_wo_R2C2nd_wo_merge_12_2_18_23/ifc_merge/12_2_18_34/output2_inliers.pkl", 'rb'))
        if 0:
            compute_confidence_mp(lst_cyn, lst_pc)  # 20251120, mcwei, compute confidence.
            for thr_coverage in tqdm([0, 0.2], 'filter_and_save_ifc with coverage...'):
                filter_and_save_ifc(logger, lst_cyn, path_cyn_file, thr_conf=thr_coverage, color=True, str_conf='coverage')
            for thr_CCR in tqdm([0, 0.15, 0.3], 'filter_and_save_ifc with CCR ...'):
                filter_and_save_ifc(logger, lst_cyn, path_cyn_file, thr_conf=thr_CCR, color=True, str_conf='CCR')

    # Add bbox to each cyn.
    for i in range(len(lst_cyn)):
        lst_cyn[i]['bbox'] = convert_cylinder2bbox(lst_cyn[i])
        lst_cyn[i]['bbox_extend'] = convert_cylinder2bbox(lst_cyn[i], THR_FILTER_BBOX_TOLERANCE)

    dir_cyn = args.path_cyns
    dir_save = (dir_cyn if os.path.isdir(dir_cyn) else os.path.dirname(dir_cyn)).replace(
        'save_for_vis', f'ifc_merge/{now.month}_{now.day}_{now.hour}_{now.minute}')
    os.makedirs(dir_save, exist_ok=True)
    if not just_for_debug:
        pickle.dump(lst_cyn, open(f"{dir_save}/output2_cyns.pkl", 'wb'))
        pickle.dump(lst_pc, open(f"{dir_save}/output2_inliers.pkl", 'wb'))

    num_cyn = len(lst_cyn)

    # 1. 删除 inlier 点太少的
    mask_low_inlier = np.array([len(pc) > THR_FILTER_MIN_NUM_INLIER for pc in lst_pc])

    # 2. 删除太短的
    mask_short = np.array([cyn['length'] > THR_FILTER_MIN_LEN for cyn in lst_cyn])

    mask_judge_by_inlier = np.ones(num_cyn, dtype=bool)
    # 遍历所有 pair：
    order = np.argsort([cyn['length'] for cyn in lst_cyn])  # 先用长度排个序，从短的开始删除
    lst_cyn_sort_by_len = [lst_cyn[o] for o in order]
    lst_pc_sort_by_len = [lst_pc[o] for o in order]

    lst_args = []
    for idx1 in range(num_cyn):
        for idx2 in range(idx1 + 1, num_cyn):
            lst_args.append((idx1, idx2))

    if logger: logger.debug(f"start multi-proc for judge bbox intersect")
    lst_ind = callback_multiprocessing(
        judge_bbox_intersect,
        lst_args,
        8,
        batch_size=1000,
        init_worker=init_worker,
        initargs=lst_cyn_sort_by_len
    )

    lst_ind = [ind for ind in lst_ind if ind is not None]

    if logger: logger.debug(f"start filter single, cnt is {len(lst_ind)}")
    #here too slow, costing more than 10hours for NRDK data.
    for idx1, idx2 in tqdm(lst_ind):
        cyn1 = lst_cyn_sort_by_len[idx1]
        cyn2 = lst_cyn_sort_by_len[idx2]
        pc1 = lst_pc_sort_by_len[idx1]
        pc2 = lst_pc_sort_by_len[idx2]
        ind = filter_single(idx1, idx2, cyn1, cyn2, pc1, pc2)
        for idx in ind:
            mask_judge_by_inlier[order[idx]] = False

    mask = mask_low_inlier & mask_short & mask_judge_by_inlier

    if logger: logger.debug('start compute confidence mp')
    compute_confidence_mp(lst_cyn, lst_pc)  # 20251120, mcwei, compute confidence.
    if logger: logger.debug('finish compute confidence mp')

    path_cyn_file = check_io_of_filtering(lst_cyn, lst_pc, mask, args.path_cyns)  # 保存最终结果

    lst_cyn_filtered = [lst_cyn[i] for i in range(num_cyn) if mask[i]]
    lst_pc_filtered = [lst_pc[i] for i in range(num_cyn) if mask[i]]

    #多输出几个ifc文件. 1. 保存的 IFC 文件时 confidence 作为伪彩色；删掉 confidence 小于某个阈值的圆柱，然后保存为 IFC。
    if logger: logger.debug('start filter and save ifc')
    for thr_coverage in tqdm([0, 0.2], 'filter_and_save_ifc with coverage...'):
        filter_and_save_ifc(logger, lst_cyn_filtered, path_cyn_file, thr_conf=thr_coverage, color=True, str_conf='coverage')
    for thr_CCR in tqdm([0, 0.15, 0.3], 'filter_and_save_ifc with CCR ...'):
        filter_and_save_ifc(logger, lst_cyn_filtered, path_cyn_file, thr_conf=thr_CCR, color=True, str_conf='CCR')
    if logger: logger.debug('finish filter and save ifc')

    return lst_cyn_filtered, lst_pc_filtered

def load_cyns_and_pcs(dir_cyn):
    lst_cyn = []
    dic_uid2pc = {}
    dic_uid2bbox = {}
    lst_path_res_fitting = glob.glob(os.path.join(dir_cyn))
    lst_path_res_fitting.sort()
    for path_res_fitting in tqdm(lst_path_res_fitting, 'Loading fitting results.'):
        res_fitting = pickle.load(open(path_res_fitting, 'rb'))
        """
        Outputs of components fitting.
        res_fitting is a dict, 
        res_fitting['ind_pts'] is a point indice. pc[res_fitting['ind_pts']] is the input points of component fitting.
            res_fitting['ind_pts'] = np.arange(n_pc), which is useless
        res_fitting['results'] is the component fitting result. It is a list.
        res_fitting['ind_pts'][i] is the information of a fitted cylinder.
        res_fitting['ind_pts'][i]['ind_clustered'] is the point indice of a cluster. Use it to index pc[res_fitting['ind_pts']].
        res_fitting['ind_pts'][i]['ind_inlier'] is the inlier point indice.  Use it to index pc[res_fitting['ind_pts']].
        res_fitting['ind_pts'][i]['d'] is the estimated pipe direction (for all points) using predicted normals.
        res_fitting['ind_pts'][i]['pc_clustered']: (n, 3)
        res_fitting['ind_pts'][i]['id_in_block']
        res_fitting['ind_pts'][i]['start'] 
        res_fitting['ind_pts'][i]['end']
        res_fitting['ind_pts'][i]['radius']
        res_fitting['ind_pts'][i]['length']
        """
        # Add block name into each cyn.
        for cyn in res_fitting['results']:
            if cyn is None or 'start' not in cyn: continue
            cyn['block'] = os.path.basename(path_res_fitting).strip('.pts.pkl')
            assert 'unified_id' in cyn, 'error. should have unified id.'
            lst_cyn.append(cyn)

    for i, cyn in tqdm(enumerate(lst_cyn), 'Formatting input cylinders and pcs...'):
        direction = np.subtract(cyn['end'], cyn['start'])
        norm = np.linalg.norm(direction)
        if norm != 0:
            direction = direction / norm
        cyn['direction'] = direction
        cyn['uid'] = i
        pc_clustered = cyn.pop('pc_clustered')
        dic_uid2pc[i] = pc_clustered
        cyn.pop('ind_inlier')
        cyn.pop('ind_clustered')
        cyn.pop('d')
        dic_uid2bbox[i] = [pc_clustered[:, :3].min(0), pc_clustered[:, :3].max(0)]

    return lst_cyn, dic_uid2pc, dic_uid2bbox

#to check its results.
observed_set = [7042,] #[6164,]
observed_set_vals = {}

def is_specific_cyn(cyn, length, diameter):
    return math.isclose(cyn['length'], length, abs_tol=0.002) and math.isclose(cyn['radius'], diameter/2.0, abs_tol=0.002)

#lst_cyns is a list, each item is a dict with keys ['ind_clustered', 'ind_inlier', 'd', 'start', 'end', 'radius', 'length', 'block', 'direction', 'uid']
def find_specific_cyn(lst_cyns):
    found_idx = []
    for i, cyn in enumerate(lst_cyns):
        #if is_specific_cyn(cyn, 3.003, 0.266159): #x-dir     #[6164, 7042, 11206], 6164最接近 3.003, 0.2661607
        if is_specific_cyn(cyn, 2.69062, 0.093043): #still x-dir
            found_idx.append(i)
    return found_idx

def merge_main(thr_cluster_direction=THR_CLUSTER_DIRECTION, thr_centerline_dist=THR_CENTERLINE_DIST, pts_path=None):
    global observed_set
    handlers = init_log()
    g_logger[0].debug(f"start merge.  now is {now}")
    t0 = time.time()

    if 0: #just for debug.
        lst_cyn_f_all_filtered = filter_cyns_mp(None, None, g_logger[0])

    #load all cyns.
    if 1: #1116, from mc's merge_cyn_dir8.py (1114 version)
        g_logger[0].debug(f"try new loading cyns and pcs")
        try:
            lst_cyns, dic_uid2pc, dic_uid2bbox = load_cyns_and_pcs(args.path_cyns)
        except Exception as e:
            print(e)
            g_logger[0].debug(f"new loading fails: {e}. still use old loading.")
            lst_cyns = load_cyns(args.path_cyns)  #todo: 目前没有coverage信息，考虑加上？
            dic_uid2pc,dic_uid2bbox = get_pc_of_cyns(args.path_cyns, lst_cyns, merge_pc=False, pts_path=pts_path)  #对于lst_cyns的每个圆柱，得到对应的点云.
    else: #org code.
        lst_cyns = load_cyns(args.path_cyns)  #目前没有coverage信息，考虑加上？
        dic_uid2pc,dic_uid2bbox = get_pc_of_cyns(args.path_cyns, lst_cyns, merge_pc=False, pts_path=pts_path)  #对于lst_cyns的每个圆柱，得到对应的点云.
    len_input = sum([np.linalg.norm(np.subtract(i['start'], i['end'])) for i in lst_cyns])
    num_input = len(lst_cyns)
    g_logger[0].debug(f"finish loading all cyns and pcs. total cyn num {len(lst_cyns)}, length {len_input:.2f}")
    t1 = time.time()  #t1-t0, data loading time.
    
    #lst_cyns is a list, each item is a dict with keys ['ind_clustered', 'ind_inlier', 'd', 'start', 'end', 'radius', 'length', 'block', 'direction', 'uid']
    #we use 'uid' as the id for each fitted cyn.
    observed_set = find_specific_cyn(lst_cyns)
    for val in observed_set: observed_set_vals[val] = {}

    #利用方向的prior信息聚类.
    dict_cyns_each_direction = cluster_with_direction(lst_cyns, gt_directions, thr_cluster_direction)
    print(f"observed set vals: {observed_set_vals}")
    if for_debug: pdb.set_trace()

    cnt_cluster_each_dir = [len(aa) for aa in dict_cyns_each_direction.values()]
    g_logger[0].debug(f"finish clustering with prior direction")
    g_logger[0].debug(f"cluster num for each dir: {cnt_cluster_each_dir[:-1]}")
    g_logger[0].debug(f"cluster num not in any gt dir: {cnt_cluster_each_dir[-1]}")
    t2 = time.time()  #t2-t1, cluster with direction.

    # color_cyns_by_angle_to_ifc(dict_cyns_each_direction, args.path_cyns)  # 对 angle 聚类后的 cyns 进行可视化，每一个方向的 cyns 一种颜色。

    #按不同centerline进行聚类.
    dict_cyns_each_centerline1 = {}  # 第一次 merge 的输出
    dict_cyns_each_centerline2 = {}  # 第二次 merge 的输出
    dict_cyns_each_direction_output = {}
    lst_pc_all = []
    lst_pc_f_all = []
    lst_cyn_f_all = []
    time_each_dir = [] #time for each direction.
    #for i in range(gt_directions.shape[0]): #只处理每个方向的，先忽略那些和所有方向都不相同的.
    for i in range(len(dict_cyns_each_direction)): #最后一个类是unknown_dir.
        tt0 = time.time()
        if for_debug and i!=8: continue
        if i<gt_directions.shape[0]:
            g_logger[0].debug(f"direction {i}: {gt_directions[i]}")
            cyns_each_centerline1, cyns_each_centerline2, lst_pc, lst_cyn_f, lst_pc_f = cluster_with_centerline(dict_cyns_each_direction[i], dic_uid2pc, thr_centerline_dist, i, g_logger[0])
        else:
            assert i==gt_directions.shape[0], f'error. gt dir set wrong. {i} != {gt_directions.shape[0]}'
            cyns_each_centerline1, cyns_each_centerline2, lst_pc, lst_cyn_f, lst_pc_f = cluster_with_centerline(dict_cyns_each_direction[i], dic_uid2pc, thr_centerline_dist, UNKNOWN_DIR, g_logger[0])
        dict_cyns_each_centerline1[i] = cyns_each_centerline1
        dict_cyns_each_centerline2[i] = cyns_each_centerline2
        dict_cyns_each_direction_output[i] = [cyns['cylinder'] for cyns in cyns_each_centerline1.values() if cyns['cylinder']]
        lst_pc_all.extend(lst_pc)
        lst_pc_f_all.extend(lst_pc_f)
        lst_cyn_f_all.extend(lst_cyn_f)
        tt1 = time.time()
        time_each_dir.append((tt1-tt0)/60) #min.

    t3 = time.time()  #t3-t2, cluster with centerline.
    g_logger[0].debug(f"begin filter cyns")
    num1, len1 = len(lst_cyn_f_all), sum([np.linalg.norm(np.subtract(i['start'], i['end'])) for i in lst_cyn_f_all])
    lst_cyn_f_all_filtered = filter_cyns_mp(lst_cyn_f_all, lst_pc_f_all, g_logger[0])
    #lst_cyn_f_all_filtered = lst_cyn_filtered, lst_pc_filtered
    #keys in lst_cyn_filtered: 'start', 'end', 'diameter', 'radius', 'length', 'direction', 'unified_id', 'bbox', 'bbox_extend', 'coverage', 'CCR'.
    num2, len2 = len(lst_cyn_f_all_filtered[0]), sum([np.linalg.norm(np.subtract(i['start'], i['end'])) for i in lst_cyn_f_all_filtered[0]])
    g_logger[0].debug(f"after filter cyns. All finished.")
    g_logger[0].debug(f"keys in merged cyns: {lst_cyn_f_all_filtered[0][0].keys()}")

    t4 = time.time()  #t4-t4, filter.
    g_logger[0].debug(f"total time {(t4-t0)/60:.2f}min: loading {(t1-t0)/60:.2f}min, dir_clustering {(t2-t1)/60:.2f}min, centerline_clustering {(t3-t2)/60:.2f}min, filter {(t4-t3)/60:.2f}min")
    g_logger[0].debug(f"time for each dir (min) {time_each_dir}")

    g_logger[0].debug(f"input cyns: num {num_input}, length {len_input:.2f}")
    g_logger[0].debug(f"before filtering: num {num1}, length {len1:.2f}")
    g_logger[0].debug(f"after filtering: num {num2}, length {len2:.2f}")

    # color_cyns_by_angle_to_ifc(dict_cyns_each_direction_output, args.path_cyns, name='output')  # 对 angle 聚类后的 cyns 进行可视化，每一个方向的 cyns 一种颜色。
    # check_io_of_clustering_all(dict_cyns_each_direction, dict_cyns_each_centerline1, dict_cyns_each_centerline2, lst_pc_f_all, args.path_cyns)

    for i in range(len(handlers)):
        handlers[i][0].close()
        g_logger[i].removeHandler(handlers[i][0])

if __name__ == '__main__':
    now = datetime.now()
    #pdb.set_trace()
    args = parse_args()
    PATH_OUTPUT = os.path.join(args.res_path, 'merge_log')
    os.makedirs(PATH_OUTPUT, exist_ok=True)
    merge_main(pts_path=args.pts_path)
