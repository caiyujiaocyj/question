import random
import matplotlib.pyplot as plt
from scipy.spatial import KDTree
from numpy.linalg import svd
from sklearn.neighbors import NearestNeighbors
import numpy as np
from typing import List, Tuple, Optional
# last_cluster_labels = None

def centralize_data(data, central=True):
    """
    将点云数据中心化（减去均值）并记录偏移量
    参数:
        data: 点云数据，形状为 (N, 3+) 的 NumPy 数组，前3列必须是 [x, y, z]
        central: 是否执行中心化
    返回:
        data_centralized: 中心化后的数据（如果 central=False 则返回原数据）
        offset: 三个方向的偏移量 [x_offset, y_offset, z_offset]
    """
    if not central:
        return data, np.zeros(3)  # 不中心化时返回原数据和零偏移

    # 提取前3列坐标（x, y, z）
    xyz = data[:, :3]

    # 计算各方向的均值（偏移量）
    offset = np.mean(xyz, axis=0)

    # 中心化：减去偏移量
    data_centralized = data.copy()
    data_centralized[:, :3] = xyz - offset

    return data_centralized, offset
def load_txt_data(file_path,downsample_factor=10,random_seed=1,central=False):
    '''x,y,z,nx,ny,nz,dir,radius,semantic_label'''
    data = np.loadtxt(file_path)
    # data = data[data[:,3]!='nan'] # remove ignore pcd

    sampled_indices = np.arange(len(data))
    # 随机下采样  1022b: 删掉了下采样
    #if random_seed is not None:
    #    np.random.seed(random_seed)  # 固定随机种子
    #n_samples = max(1, len(data) // downsample_factor)  # 至少保留1个点
    #sampled_indices = np.random.choice(len(data), n_samples, replace=False)
    #data = data[sampled_indices]

    # 中心化
    offset = np.zeros(3)
    if central:
        data, offset = centralize_data(data, central=True)
    # instance_id = data[:,11]
    points = data[:, :3]  # surface points
    cls = data[:, 10][:]
    normals = data[:, 3:6]  # surface normal, from surface to centerline
    radii = data[:, 9]
    # 这里是孟传的合成数据
    # pipe_mask = np.isin(cls, [17, 35])
    pipe_mask = cls==1
    surface_points = points[pipe_mask]  # keep original surface points
    surface_normals = normals[pipe_mask]
    pipe_radii = radii[pipe_mask]
    # instance_id = instance_id[pipe_mask]
    centerline_points = surface_points - pipe_radii[:, None] * surface_normals
    pipe_dirs = data[pipe_mask,6:9]  # fixed pipe direction
    # all_points = data[:, :3]
    return centerline_points, pipe_radii, surface_points, pipe_dirs, offset, sampled_indices,surface_normals
def load_pts_data(file_path):
    #points:x,y,z,r,nx,ny,nz,
    data = np.loadtxt(file_path)
    points = data[:, :3]  # surface points
    cls = data[:, 10:13]
    normals = data[:, 4:7]
    normalss = np.linalg.norm(normals,axis=1,keepdims=True)+1e-8# surface normal, from surface to centerline
    normals = normals/normalss
    radii = data[:, 3]
    pipe_mask = cls[:,1]==cls[:,2]
    print(pipe_mask.sum())
    surface_points = points[pipe_mask]  # keep original surface points
    surface_normals = normals[pipe_mask]
    pipe_radii = radii[pipe_mask]
    # 法线朝外
    centerline_points = surface_points - pipe_radii[:, None] * surface_normals
    # 方向假设
    pipe_dirs = np.tile(np.array([[0, 1, 0]]), (len(centerline_points), 1))  # fixed pipe direction
    all_points = data[:, :3]
    return centerline_points, pipe_radii, surface_points, pipe_dirs
def load_np_data(file_path):

    """
    Load npy file with [x, y, z, seg, radius, normal_x, normal_y, normal_z].
    Returns:
        xyz: [N, 3] array of coordinates
        seg: [N] segmentation mask
        radius: [N] radius values
        normal: [N, 3] normal vectors
    """
    data = np.load(file_path).astype(np.float32)
    points = data[:, :3]  # surface points
    cls = data[:, 3]
    normals = data[:, 5:8]  # surface normal, from surface to centerline
    radii = data[:, 4]
    pipe_mask = cls >0
    #np.set_printoptions(threshold=np.inf)
    print(pipe_mask.sum())
    surface_points = points[pipe_mask]  # keep original surface points
    surface_normals = normals[pipe_mask]
    pipe_radii = radii[pipe_mask]
    centerline_points = surface_points - pipe_radii[:, None] * surface_normals
    pipe_dirs = np.tile(np.array([[0, 1, 0]]), (len(centerline_points), 1))  # fixed pipe direction
    all_points = data[:, :3]
    return centerline_points, pipe_radii, surface_points, pipe_dirs
def instance_cluster(instance_id):
    # Get unique instance IDs
    unique_ids = np.unique(instance_id)

    # Create a dictionary to map instance_id to label
    id_to_label = {id_: idx for idx, id_ in enumerate(unique_ids)}

    # Convert instance_id array to labels
    labels = np.array([id_to_label[id_] for id_ in instance_id], dtype=np.int32)

    return labels

def region_growing_with_direction(points, directions, radius=0.2, angle_threshold=np.deg2rad(30), min_points=10):
    nbrs = NearestNeighbors(radius=radius).fit(points)
    all_neighbors = nbrs.radius_neighbors(points, return_distance=False)
    visited = np.zeros(len(points), dtype=bool)
    labels = -1 * np.ones(len(points), dtype=int)
    current_label = 0
    norm_directions = directions / (np.linalg.norm(directions, axis=1, keepdims=True) + 1e-6)
    cos_threshold = np.cos(angle_threshold)

    for i in range(len(points)):
        if visited[i]:
            continue
        queue = [i]
        visited[i] = True
        segment = []

        while queue:
            idx = queue.pop()
            segment.append(idx)
            # neighbors = nbrs.radius_neighbors([points[idx]], return_distance=False)[0]
            neighbors = all_neighbors[idx]
            for n_idx in neighbors:
                if visited[n_idx]:
                    continue
                # ang = angle_between(directions[idx], directions[n_idx])
                # if ang < angle_threshold:
                if np.dot(norm_directions[idx], norm_directions[n_idx]) > cos_threshold:
                    visited[n_idx] = True
                    queue.append(n_idx)

        if len(segment) >= min_points:
            for idx in segment:
                labels[idx] = current_label
            current_label += 1
# 15 only
#     print(len(np.unique(labels)))
    return labels


def region_growing_with_direction_optimized(points, directions, radius=0.2, angle_threshold=np.deg2rad(30),
                                            min_points=10, down_sample_factor=10):
    """
    优化版本的区域生长算法，先下采样再聚类，然后用聚类中心作为种子点进行全量点云区域生长

    参数:
        points: 原始点云坐标 (N, 3)
        directions: 每个点的方向向量 (N, 3)
        radius: 邻域搜索半径
        angle_threshold: 方向相似性阈值(弧度)
        min_points: 最小聚类点数
        down_sample_factor: 下采样因子

    返回:
        labels: 每个点的聚类标签 (N,)
    """
    # Step 1: 对点云进行随机下采样
    N = len(points)
    if N < min_points:
        return -1 * np.ones(N, dtype=int)
    idx = np.random.choice(N, N // down_sample_factor, replace=False)
    downsampled_points = points[idx]
    downsampled_directions = directions[idx]

    # Step 2: 在下采样的点云上应用原始聚类算法
    downsampled_labels = region_growing_with_direction(
        downsampled_points, downsampled_directions,
        radius, angle_threshold, min_points
    )
    unique_labels = np.unique(downsampled_labels)
    unique_labels = unique_labels[unique_labels >= 0]  # 移除噪声点标签(-1)

    # Step 3: 用所有下采样聚类点（不仅是中心）作为种子点
    tree_full = KDTree(points)
    labels_full = -1 * np.ones(N, dtype=int)

    for label in unique_labels:
        # 获取当前聚类内的所有下采样点
        seed_mask = (downsampled_labels == label)
        cluster_seeds = downsampled_points[seed_mask]

        # 对每个种子点，标记其原始点云中的邻域点
        for seed in cluster_seeds:
            neighbor_indices = tree_full.query_ball_point(seed, r=radius)

            # 只标记未被分配或距离更近的点（避免重复覆盖）
            for idx in neighbor_indices:
                # if labels_full[idx] == -1:  # 未分配标签的点直接标记
                labels_full[idx] = label

    return labels_full


# zhh: 差别是，用一个子集来作为搜索邻域的种子点
def region_growing_with_direction2(points, directions, idx_seeds, radius=0.2, angle_threshold=np.deg2rad(30),
                                   min_points=10):
    nbrs = NearestNeighbors(radius=radius).fit(points)
    points_seeds = points[idx_seeds]
    labels = -1 * np.ones(len(points), dtype=int)
    if points_seeds.shape[0]==0:
        return labels
    all_neighbors = nbrs.radius_neighbors(points_seeds, return_distance=False)

    # 全集中向seed集的指针，-1表示不在seed中
    idx_full2seed = [-1, ] * len(points)
    for id_seed in range(len(idx_seeds)): idx_full2seed[idx_seeds[id_seed]] = id_seed

    visited = np.zeros(len(points), dtype=bool)
    
    current_label = 0
    norm_directions = directions / (np.linalg.norm(directions, axis=1, keepdims=True) + 1e-6)
    cos_threshold = np.cos(angle_threshold)

    for id_seed in range(len(idx_seeds)):
        i = idx_seeds[id_seed]  # i转成全集的idx.
        assert idx_full2seed[i] == id_seed, 'wrong. data not consistent.'
        if visited[i]: continue
        queue = [i]  # 这里保存的是seed点，不过值表示fullset中的index.
        visited[i] = True
        segment = [i, ]  # 这里是full点集中的点

        while queue:
            idx = queue.pop()
            # segment.append(idx)
            # neighbors = nbrs.radius_neighbors([points[idx]], return_distance=False)[0]
            neighbors = all_neighbors[idx_full2seed[idx]]
            for n_idx in neighbors:
                if visited[n_idx]:
                    continue
                # ang = angle_between(directions[idx], directions[n_idx])
                # if ang < angle_threshold:
                if np.dot(norm_directions[idx], norm_directions[n_idx])> cos_threshold: # modify yw
                    visited[n_idx] = True
                    segment.append(n_idx)
                    if idx_full2seed[n_idx] >= 0: queue.append(n_idx)

        if len(segment) >= min_points:
            for idx in segment:
                labels[idx] = current_label
            current_label += 1
    # 15 only
    #     print(len(np.unique(labels)))
    return labels


# 张辉 updated: 打算实现相同的功能.
def region_growing_with_direction_optimized2(points, directions, radius=0.2, angle_threshold=np.deg2rad(30),
                                             min_points=10, down_sample_factor=10):
    """
    优化版本的区域生长算法，先下采样再聚类，然后用聚类中心作为种子点进行全量点云区域生长

    参数:
        points: 原始点云坐标 (N, 3)
        directions: 每个点的方向向量 (N, 3)
        radius: 邻域搜索半径
        angle_threshold: 方向相似性阈值(弧度)
        min_points: 最小聚类点数
        down_sample_factor: 下采样因子

    返回:
        labels: 每个点的聚类标签 (N,)
    """
    # Step 1: 对点云进行随机下采样
    N = len(points)
    if N < min_points:
        return -1 * np.ones(N, dtype=int)
    idx = np.random.choice(N, N // down_sample_factor, replace=False)
    # downsampled_points = points[idx]
    # downsampled_directions = directions[idx]

    # Step 2: 在下采样的点云上应用原始聚类算法
    labels_full = region_growing_with_direction2(points, directions, idx, radius, angle_threshold, min_points)
    return labels_full

def hierarchical_region_growing(points, directions, initial_labels=None,radius=0.02, angle_threshold=np.deg2rad(30), min_points=30):
    """
    分层区域增长聚类（直接调用原函数）

    参数：
        points : (N,3) array           # 点云坐标
        directions : (N,3) array       # 方向向量
        initial_labels : (N,) array    # 初始分组标签（None表示不分组）
        **kwargs :                      # 传递给原函数的参数
            radius, angle_threshold, min_points等

    返回：
        final_labels : (N,) array      # 最终聚类标签（保持原函数的-1表示噪声）
    """
    if initial_labels is None:
        # 如果没有初始标签，直接调用原函数
        # return region_growing_with_direction(points, directions, radius, angle_threshold, min_points)
        return region_growing_with_direction_optimized2(points, directions, radius, angle_threshold, min_points)
    final_labels = -1 * np.ones_like(initial_labels)
    label_offset = 0

    # 对每个初始组单独处理
    for group_id in np.unique(initial_labels):
        group_mask = (initial_labels == group_id)
        group_points = points[group_mask]
        group_directions = directions[group_mask]

        # 调用原函数处理当前组
        # group_labels = region_growing_with_direction(group_points,group_directions,radius, angle_threshold, min_points)
        group_labels = region_growing_with_direction_optimized2(group_points, group_directions, radius, angle_threshold, min_points)
        # 将当前组的有效标签（非-1）映射到全局标签空间
        valid_mask = (group_labels != -1)
        final_labels[group_mask] = np.where(
            valid_mask,
            group_labels + label_offset,
            -1
        )

        # 更新标签偏移量（取当前组最大标签+1）
        if np.any(valid_mask):
            label_offset += np.max(group_labels[valid_mask]) + 1

    return final_labels
def radius_cluster(points, radius, dir, atol=0.001, enable_dir_clustering=True, angle_threshold=5.0):
    """
    按半径和方向向量对点云进行分组，支持方向分类开关和固定方向（x/y/z轴）的快速匹配。

    参数:
        points : np.ndarray (N, 3)
            输入点云坐标。
        radius : np.ndarray (N,)
            每个点的半径。
        dir : np.ndarray (N, 3)
            单位方向向量（允许微小偏差）。
        atol : float, default=0.001
            半径分组的误差范围。
        enable_dir_clustering : bool, default=True
            是否启用方向分类。若为False，则仅按半径分组。
        angle_threshold : float, default=5.0
            方向匹配的角度阈值（单位：度），仅当 enable_dir_clustering=True 时生效。

    返回:
        labels : np.ndarray (N,)
            每个点的组标签（从0开始）。
    """
    labels = np.full(len(points), -1, dtype=int)
    current_label = 0

    # 1. 按半径分组
    unique_radii = np.unique(np.round(radius, decimals=6))

    for r in unique_radii:
        mask = np.isclose(radius, r, atol=atol)
        group_indices = np.where(mask)[0]  # 当前半径组的原始索引

        if len(group_indices) == 0:
            continue

        # 2. 如果启用方向分类，则进一步分组
        if enable_dir_clustering:
            group_dirs = dir[group_indices]

            # 定义基准方向：x/y/z轴
            ref_directions = np.array([
                [1, 0, 0],  # x轴
                [0, 1, 0],  # y轴
                [0, 0, 1]  # z轴
            ])

            # 计算每个点与三个基准方向的余弦相似度
            cosine_sim = np.abs(np.dot(group_dirs, ref_directions.T))  # (M, 3)
            # cosine_sim = np.dot(group_dirs, ref_directions.T)  # (M, 3)

            max_cosine = np.max(cosine_sim, axis=1)
            best_match = np.argmax(cosine_sim, axis=1)  # 每个点最接近的基准方向索引

            # 检查是否超过角度阈值（余弦值 >= cos(angle_threshold)）
            cos_threshold = np.cos(np.deg2rad(angle_threshold))
            valid_mask = (max_cosine >= cos_threshold)

            # 分配标签：有效点按基准方向分组，无效点单独分组
            for ref_idx in range(3):
                dir_mask = (best_match == ref_idx) & valid_mask
                if np.any(dir_mask):
                    labels[group_indices[dir_mask]] = current_label
                    current_label += 1

            # 处理无效点（方向不匹配任何基准）
            # invalid_mask = ~valid_mask
            # if np.any(invalid_mask):
            #     labels[group_indices[invalid_mask]] = current_label
            #     current_label += 1        
        else:
            # 不启用方向分类，直接分配同一标签
            labels[group_indices] = current_label
            current_label += 1

    return labels

def dir_est(sur_normals, lbl):
    # 获取所有唯一的标签
    unique_labels = np.unique(lbl)
    # 初始化结果数组，形状与 sur_normals 相同
    a_est = np.zeros_like(sur_normals)

    for i in unique_labels:
        # 获取当前标签对应的法向量
        if i==-1:
            continue
        mask = (lbl == i)
        sur_normal = sur_normals[mask]

        # 检查是否有足够的样本（至少 3 个点）
        if sur_normal.shape[0] >= 3:
            # 计算 SVD
            _, _, Vt = svd(sur_normal, full_matrices=False)
            # 最小奇异值对应的向量（Vt 的最后一行）
            min_singular_vector = Vt[-1]
            # 将结果填充到对应位置
            a_est[mask] = min_singular_vector
        else:
            # 如果样本不足，填充零向量或跳过
            a_est[mask] = np.zeros(3)
    return a_est

def ransac_line_fitting_with_direction(points, directions, max_iterations=100, distance_threshold=0.02,
                                        min_inliers_ratio=0.4, angle_threshold=np.deg2rad(15)):
    # distance_threshold important
    best_inlier_count = 0
    best_model = None
    n_points = len(points)
    min_inliers = int(n_points * min_inliers_ratio)

    def angle_between(v1, v2):
        v1 = v1 / (np.linalg.norm(v1) + 1e-6)
        v2 = v2 / (np.linalg.norm(v2) + 1e-6)
        return np.arccos(np.clip(np.dot(v1, v2), -1.0, 1.0))

    for _ in range(max_iterations):
        idx = np.random.choice(n_points, 2, replace=False)
        p1, p2 = points[idx]
        direction = p2 - p1
        if np.linalg.norm(direction) < 1e-6:
            continue
        direction = direction / np.linalg.norm(direction)

        vecs = points - p1
        projections = np.dot(vecs, direction)[:, np.newaxis] * direction
        dists = np.linalg.norm(vecs - projections, axis=1)
        inlier_mask = dists < distance_threshold

        if np.sum(inlier_mask) < min_inliers:
            continue

        avg_angle = np.mean([angle_between(direction, d) for d in directions[inlier_mask]])
        if avg_angle > angle_threshold:
            continue

        inlier_count = np.sum(inlier_mask)
        if inlier_count > best_inlier_count:
            best_inlier_count = inlier_count
            best_model = (direction, p1.copy(), inlier_mask)

    if best_model is not None:
        return best_model
    else:
        return None, None, np.ones(n_points, dtype=bool)
def ransac_lines_fitting_with_direction(remaining_points, remaining_dirs, threshold=0.005,
                                       max_iterations=1000, min_inliers=100):
    """
    使用RANSAC算法拟合具有特定方向的直线。

    参数:
        remaining_points (numpy.ndarray): 点集，形状为 (n, 3)。
        remaining_dirs (numpy.ndarray): 点所在直线的方向，形状为 (n, 3)。
        threshold (float): 内点距离阈值，默认为 0.1。
        max_iterations (int): 最大迭代次数，默认为 1000。
        min_inliers (int): 最小内点数量，默认为 30。

    返回:
        direction (numpy.ndarray): 拟合直线的方向，形状为 (3,)。
        point_on_line (numpy.ndarray): 拟合直线上的一个点，形状为 (3,)。
        inlier_mask (numpy.ndarray): 内点掩码，形状为 (n,)，布尔类型。
        如果内点数量不足，返回 (None, None, None)
    """

    if len(remaining_points) < min_inliers:
        return None, None, None

    n = remaining_points.shape[0]
    best_inlier_count = 0
    best_direction = None
    best_point_on_line = None
    best_inlier_mask = None

    for _ in range(max_iterations):
        # 随机选择一个点作为直线上的点
        idx = np.random.randint(n)
        point_on_line = remaining_points[idx]
        direction = remaining_dirs[idx]

        # 归一化方向向量
        norm = np.linalg.norm(direction)
        if norm < 1e-10:  # 避免零向量
            continue
        norm_direction = direction / norm

        # 计算所有点到直线的距离
        vectors = remaining_points - point_on_line
        cross_products = np.cross(vectors, norm_direction)
        distances = np.linalg.norm(cross_products, axis=1)

        # 确定内点
        inlier_mask = distances < threshold
        inlier_count = np.sum(inlier_mask)
        if inlier_count < min_inliers:
            continue
        # 提前终止：如果当前内点已经远超过历史最佳
        if inlier_count > best_inlier_count and inlier_count >= min_inliers:
            best_inlier_count = inlier_count
            best_direction = norm_direction
            best_point_on_line = point_on_line
            best_inlier_mask = inlier_mask

            # 提前终止条件：如果找到足够多的内点
            if inlier_count > 0.9 * n:  # 90%的点都是内点
                break

    # 检查最终内点数量是否满足要求
    if best_inlier_count < min_inliers:
        return None, None, None

    # 使用所有内点重新拟合直线
    inlier_points = remaining_points[best_inlier_mask]
    best_point_on_line = np.mean(inlier_points, axis=0)  # 使用内点的均值作为直线上的点

    # 方向取内点方向的平均值并归一化
    inlier_dirs = remaining_dirs[best_inlier_mask]
    best_direction = np.mean(inlier_dirs, axis=0)
    norm = np.linalg.norm(best_direction)
    if norm < 1e-10:  # 处理零向量情况
        best_direction = np.array([1.0, 0.0, 0.0])  # 默认方向
    else:
        best_direction = best_direction / norm

    return best_direction, best_point_on_line, best_inlier_mask
